 - - - PCA - - -
 - compute
demean data
 X = X - mean(X)
cov matrix
 C = X*X' / (M - 1)
eig decomposition
 [vect, val] = eig(C)
 [eigenvalues,idx] = sort(diag(val),'descend')
 [eigenvectors] = vect(:,idx)
 - project
Ap = eigenvectors(:,1:p)' 
Y = Ap ( X - Mu)

 - reconstruct
Xhat = pinv(Ap) * Y + Mu

 - reconstruction_error
norm(X-Xhat, 2)

 - compress image
for i=1:3
   compute
   project

 - reconstruct image
for i =1:3
    reconstructpca

 - normalize
  minmax
    x = (data - min) / (max - min)
      //data==min -> X = 0
      //data==max -> X = 1

  zscore
    x = (data - mean) / stddev

 
 - - - KMEANS - - - 
 - init
  datasample from centroids
        Mu = X(:,randsample(M,k));
  range
    rand in minmax

 - compute_distance
  norm

 - distance_to_centroids
  distance of each point to each centroid


 - check_convergenze
   return true if compute_distance(Mu,Mu_previous) < tolerance for more than maxTolIter iterations


================================================TODO kmeans function


 - - - KNN - - - 

KNN

 K pari per classi dispari / viceversa / This avoids ties during the majority voting step

  foreach test point
    compute distance to each point in dataset
    sort distances and take first Ks
    mode of the first Ks

accuracy
    accuracy = sum(y_test==y_est) / M

knn_eval
  for each k in k_range
    y_est = knn
    acc_curve(i) = accuracy()


confusion matrix

  foreach point
    if y_test=1 and y_est=1 true positive
    if y_test=0 and y_est=0 true negative
    if y_test=1 and y_est=0 false negative
    if y_test=0 and y_est=1 false positive
  matrix
    |TP & FN|
    |FP & TN|

knn_ROC
  TP_rate = TP/P = TP/(TP+FN)
  FP_rate = FP/N = FP/(TN+FP)
  computed for k in k_range


cross_validation
  do the roc for various folds

  give you the avg/std of the roc for each k



 - - - GMM - - - 

prob = gaussPDF(X, Mu, Sigma)
prob = (1xM)

logl = gmmLogLik(X, Priors, Mu, Sigma)
logl = 1x1


Sigma = compute_covariance( X, X_bar, type )
X_bar = mean(X)
Sigma = NxN matrix
type = full/diag/iso


Priors0, Mu0, Sigma0, labels0 = gmmInit(X, params)
params = cov_type, kmeans: k, d_type (distance), init type, max_iter_init

Priors0 uniformi 1/K
Mu0 da kmeans
Sigma0 con compute_covariance
labels0 da kmeans


Pk_x = expectation_step(X, Priors, Mu, Sigma, params)
Pk_x(KxM) posterior probability that a k gaussian is responsible for generating a point m in the dataset p(punto mesimo | x si distribuisce come una gaussiana)


Priors,Mu,Sigma = maximization_step(X, Pk_x, params)
Compute the maximization step of the EM algorithm

Priors, Mu, Sigma, iter = gmmEM(X, params)
gmmInit
and then cycles on expectation/maximization until convergence of the loglikelihood

AIC, BIC =  gmm_metrics(X, Priors, Mu, Sigma, cov_type)
AIC = -2*logl + 2 * B;
BIC = -2 * logl + log(M) * B;


AIC_curve, BIC_curve =  gmm_eval(X, K_range, repeats, params)
takes the minimum of each aic/bic for repeats iterations for each k






